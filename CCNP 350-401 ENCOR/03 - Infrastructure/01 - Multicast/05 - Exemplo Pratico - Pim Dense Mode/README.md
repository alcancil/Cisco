# Ãndice

- [Ãndice](#Ã­ndice)
  - [05 - Exemplo PrÃ¡tico - PIM Dense Mode](#05---exemplo-prÃ¡tico---pim-dense-mode)
    - [ExplicaÃ§Ã£o do CenÃ¡rio](#explicaÃ§Ã£o-do-cenÃ¡rio)
    - [Testes Preliminares](#testes-preliminares)
    - [Onde o PIM deve ser ativado](#onde-o-pim-deve-ser-ativado)
  - [FunÃ§Ã£o do DR no PIM Dense Mode](#funÃ§Ã£o-do-dr-no-pim-dense-mode)
    - [Contexto: Por que o PIM precisa de um DR?](#contexto-por-que-o-pim-precisa-de-um-dr)
    - [Processo de EleiÃ§Ã£o do DR no PIM Dense Mode](#processo-de-eleiÃ§Ã£o-do-dr-no-pim-dense-mode)
    - [FunÃ§Ã£o prÃ¡tica do DR no PIM Dense Mode](#funÃ§Ã£o-prÃ¡tica-do-dr-no-pim-dense-mode)
    - [Resumo rÃ¡pido](#resumo-rÃ¡pido)
  - [EndereÃ§o Multicast 224.0.0.13](#endereÃ§o-multicast-2240013)
    - [RevisÃ£o](#revisÃ£o)
    - [Resumo prÃ¡tico](#resumo-prÃ¡tico)

## 05 - Exemplo PrÃ¡tico - PIM Dense Mode

### ExplicaÃ§Ã£o do CenÃ¡rio

Agora que vimos a teoria Ã© hora de praticar. A primeira coisa que precisa ser dita que o **multicast Ã© um serviÃ§o** e, portanto, precisamos aplicar ele em um cenÃ¡rio que jÃ¡ estÃ¡ pronto e funcional.  

![cenÃ¡rio](Imagens/cenario.png)  

Nesse cenÃ¡rio estamos utilizando **seis roteadores**.  

Sim, isso mesmo â€” os â€œhostsâ€ sÃ£o, na verdade, **roteadores disfarÃ§ados de hosts**, e por isso nÃ£o realizaremos muitas configuraÃ§Ãµes neles.  

Nos demais roteadores, que estÃ£o interligados entre si, foi configurado apenas o protocolo de roteamento dinÃ¢mico **OSPF**, garantindo que todas as redes jÃ¡ possuam **conectividade IP completa** antes de ativarmos o multicast.  

O que precisamos entender aqui Ã© que o **PIM Dense Mode** funciona segundo o princÃ­pio **â€œflood and pruneâ€**.  
Mas o que isso significa?  

Quando o processo de comunicaÃ§Ã£o multicast se inicia, o protocolo PIM envia o trÃ¡fego multicast por todos os caminhos possÃ­veis (flood), **atÃ© descobrir quais roteadores possuem receptores interessados** naquele grupo multicast.  
Os caminhos que **nÃ£o possuem hosts interessados** sÃ£o posteriormente **â€œpodadosâ€ (pruned)** da Ã¡rvore de distribuiÃ§Ã£o, otimizando o fluxo.  

Nesse exemplo, o **Host01 (Server)** serÃ¡ a **fonte** da comunicaÃ§Ã£o multicast, enquanto apenas o **Host03** serÃ¡ o **receptor** interessado nesse trÃ¡fego.  

### Testes Preliminares

Agora vamos acessar o SERVER e vamos garantir que existe comunicaÃ§Ã£o entre todos os hosts.  
**OBS:** nos roteadores eu configurei interfaces de LOOPABCK. EntÃ£o R01 tem o ip 1.1.1.1 /32, R02 tem o ip 2.2.2.2 /32 e R03 tem o ip 3.3.3.3 /32 .  

![01](Imagens/01.png)

Com isso, podemos ver que todos os hosts se alcanÃ§am e se comunicam. Mas o mais importante Ã© observer a a tabela de roteamento para podermos entender um conceito simples.  

![02](Imagens/02.png)  

Essa Ã© a tabela de roteamento em R01. Estamos acostumados a analisar essa tabela para verificarmos se o roteamento dinÃ¢mico estÃ¡ funcionando corretamente e nÃ£o temos nenhum problema. PorÃ©m uma coisa que nÃ£o Ã© muito falada e que pode passar despercebida no primeiro momento Ã© que essa tabela Ã© como se fosse um bando de dados onde Ã© feito o mapeamento da comunicaÃ§Ã£o das redes que agora se dÃ¡ em **unicast**. Ou seja, um host vai se comunicar diretamente com o outro, ou seja, comunicaÃ§Ã£o de **um para um.**  

No nosso caso queremos ter a comunicaÃ§Ã£o **de um para um grupo**, ou seja, **comunicaÃ§Ã£o multicast**. EntÃ£o nosso papel aqui Ã© montar a Ã¡rvore de comuniÃ§aÃ§Ã£o que jÃ¡ foi explicada anteriormente. Essa Ã¡rvore Ã© como se fosse uma tabela de roteamento sÃ³ que agora multicast.  

EntÃ£o a primeira coisa que precisamos verificar Ã© se o **roteamento multicast estÃ¡ ativo** no equipamento.  

> R01#show ip multicast  
>  Multicast Routing: disabled  
>  Multicast Multipath: disabled  
>  Multicast Route limit: No limit  
>  Multicast Triggered RPF check: enabled  
>  Multicast Fallback group mode: Sparse  
>  Multicast DVMRP Interoperability: disabled  
>  Number of multicast boundaries configured with filter-autorp option: 0  
> R01#  

Certo, como podemos ver, o roteamento multicast nÃ£o estÃ¡ ativo. EntÃ£o vamos ativar o mesmo.  

>R01(config)#ip multicast-routing  

SÃ³ para confirmar, vamos rodar o mesmo comando mais uma vez.  

>R01#show ip multicast  
  Multicast Routing: enabled  
  Multicast Multipath: disabled  
  Multicast Route limit: No limit  
  Multicast Triggered RPF check: enabled  
  Multicast Fallback group mode: Sparse  
  Multicast DVMRP Interoperability: disabled  
  Number of multicast boundaries configured with filter-autorp option: 0  
R01#  

Agora que temos o roteamento multicast ativo, precisamos ativar o protocolo **PIM**. Esse protocolo deve ser ativado nas interfaces onde a comunicaÃ§Ã£o ira ocorrer.  

### Onde o PIM deve ser ativado

No modo **Dense Mode (PIM-DM)**, o trÃ¡fego multicast Ã© floodado por todas as interfaces que participam do domÃ­nio multicast.  

ðŸ‘‰ Portanto, vocÃª deve ativar o PIM **em todas as interfaces que participam do caminho multicast** â€” ou seja, interfaces que interligam roteadores e tambÃ©m interfaces conectadas a redes com hosts (fontes ou receptores).  

âœ… **Resumo da regra prÃ¡tica:**  

- Ative o PIM nas interfaces que tÃªm roteadores vizinhos PIM e nas interfaces onde hÃ¡ fontes ou receptores multicast.  

ðŸŒ€ **Sobre interfaces de Loopback (muito importante)**  

- NÃ£o Ã© necessÃ¡rio ativar PIM em interfaces Loopback, a menos que ela seja usada como origem do trÃ¡fego multicast (por exemplo, um servidor multicast rodando em 1.1.1.1).  

- Por padrÃ£o, o PIM trabalha nas interfaces que realmente encaminham trÃ¡fego multicast (as fÃ­sicas).  

- A Loopback costuma ser usada apenas como Router-ID, endereÃ§o de origem de OSPF/PIM, ou fonte lÃ³gica (RP) em cenÃ¡rios de Sparse Mode â€” nÃ£o Ã© o caso aqui.  

Portanto, no nosso cenÃ¡rio vamos entrar no roteador R01 vamos ativar o PIM em todas as interfaces que estÃ£o ativas e vÃ£o fazer parte do multicast.  

> R01>ena  
> R01#show ip int br  
> Interface                  IP-Address      OK? Method Status                Protocol  
> FastEthernet0/0            10.0.0.1        YES NVRAM  up                    up  
> FastEthernet0/1            10.0.0.9        YES NVRAM  up                    up  
> FastEthernet1/0            192.168.10.254  YES NVRAM  up                    up  
> Loopback0                  1.1.1.1         YES NVRAM  up                    up  
> R01#conf t  
> Enter configuration commands, one per line.  End with CNTL/Z.  
> R01(config)#int f0/0  
> R01(config-if)#ip pim dense-mode  
> R01(config-if)#  
> *Mar  1 03:53:26.735: %PIM-5-DRCHG: DR change from neighbor 0.0.0.0 to 10.0.0.1 on interface FastEthernet0/0  
> R01(config-if)#int f0/1  
> R01(config-if)#ip pim dense-mode  
> R01(config-if)#  
> *Mar  1 03:53:48.687: %PIM-5-DRCHG: DR change from neighbor 0.0.0.0 to 10.0.0.9 on interface FastEthernet0/1  
> R01(config-if)#ip pim  
> R01(config-if)#int f1/0  
> R01(config-if)#ip pim dense-mode  
> R01(config-if)#  
> *Mar  1 03:54:21.635: %PIM-5-DRCHG: DR change from neighbor 0.0.0.0 to 192.168.10.254 on interface FastEthernet1/0  
> R01(config-if)#  

Agora que ativamos o **PIM DENSE-MODE** podemos observar que nos Ã© exibida uma mensagem de aviso (log nÃ­vel 5)  
  
***Mar  1 03:54:21.635: %PIM-5-DRCHG: DR change from neighbor 0.0.0.0 to 192.168.10.254 on interface FastEthernet1/0**  
  
Essa mensagem se dÃ¡ por conta do processo de eleiÃ§Ã£o do **DR (Designated Router)**. Apesar dessa mensagem gerar uma dÃºvida, isso nÃ£o tem nada a ver com o protocolo OSPF. Apenas ocorre uma coincidÃªncia nas nomenclaturas: **DR (Designated Router)** pois nos dois protocolos Ã© mesma nomenclatura.  

## FunÃ§Ã£o do DR no PIM Dense Mode

No PIM Dense Mode, a comunicaÃ§Ã£o multicast funciona com o mÃ©todo Flood and Prune:

- Inicialmente, o trÃ¡fego multicast Ã© enviado para todos os roteadores PIM;
- Os roteadores que nÃ£o tÃªm receptores interessados enviam mensagens Prune, pedindo para parar de receber o fluxo.
- O Designated Router Ã© quem:
- Inicia o envio do fluxo multicast para a LAN;
- Coordena a poda (prune) quando nÃ£o hÃ¡ interesse local;
- Evita duplicaÃ§Ã£o de pacotes multicast quando hÃ¡ mais de um roteador conectado Ã  mesma rede.  

### Contexto: Por que o PIM precisa de um DR?  

Em uma rede multiacesso (como um segmento Ethernet), podem existir vÃ¡rios roteadores PIM conectados Ã  mesma sub-rede.  
Quando um host multicast envia trÃ¡fego para um grupo (ex: 239.1.1.1), todos os roteadores PIM na LAN recebem esse trÃ¡fego.  

- Se todos eles repassassem o fluxo multicast ao mesmo tempo, haveria duplicaÃ§Ã£o de pacotes e loops.  
  
Por isso, o PIM precisa eleger um Ãºnico roteador que serÃ¡ responsÃ¡vel por reencaminhar o trÃ¡fego multicast na LAN â€” esse Ã© o Designated Router (DR).  

### Processo de EleiÃ§Ã£o do DR no PIM Dense Mode

A eleiÃ§Ã£o Ã© baseada nas mensagens PIM Hello, trocadas periodicamente entre os roteadores.

ðŸ”¹ **Etapa 1 â€” Envio de mensagens Hello**

Todos os roteadores PIM em uma interface enviam mensagens Hello periodicamente (a cada 30 segundos por padrÃ£o).  
Essas mensagens contÃªm informaÃ§Ãµes como:  

- IP da interface de origem
- Prioridade do DR (DR Priority)
- Temporizador de Hello  

O comando **debug ip pim ou show ip pim interface** permite ver esses parÃ¢metros.

ðŸ”¹ **Etapa 2 â€” ComparaÃ§Ã£o dos parÃ¢metros**

Ao receber Hellos dos vizinhos, cada roteador compara sua prioridade com as dos outros:  

- Maior prioridade vence.
- Por padrÃ£o, o valor Ã© 1 em todos os roteadores.

Pode ser alterado com:  

> interface FastEthernet0/0
> ip pim dr-priority <valor>  

ðŸ”¹ **Etapa 3 â€” EleiÃ§Ã£o e anÃºncio do DR**

Quando um roteador identifica que ele possui a maior prioridade (ou maior IP em empate), ele se declara DR.  
O Cisco IOS registra isso com mensagens como:  

> %PIM-5-DRCHG: DR change from neighbor 0.0.0.0 to 192.168.10.254 on interface FastEthernet1/0

ðŸ“˜ InterpretaÃ§Ã£o:  

- O campo from neighbor 0.0.0.0 indica que nÃ£o havia DR anterior.
- O novo DR Ã© o roteador cujo IP Ã© 192.168.10.254 (o prÃ³prio).  

ðŸ”¹ **Etapa 4 â€” ManutenÃ§Ã£o do DR**  

Enquanto o DR estiver ativo e enviando Hellos, os outros roteadores nÃ£o tentam assumir o papel.  
Se o DR parar de enviar Hellos (por falha, interface down ou perda de conectividade), os demais roteadores detectam a ausÃªncia e refazem a eleiÃ§Ã£o automaticamente.  

### FunÃ§Ã£o prÃ¡tica do DR no PIM Dense Mode

O DR atua como ponto central para:  

- Registrar as fontes (quando hÃ¡ hosts multicast na LAN).
- Enviar os pacotes multicast iniciais no modo flood.
- Responder a mensagens IGMP vindas dos hosts receptores. 

Ou seja, o DR Ã© quem fala com os hosts (via IGMP) e com os outros roteadores (via PIM).  

**ðŸ” Exemplo prÃ¡tico**

Imagine trÃªs roteadores PIM ligados Ã  mesma rede 192.168.10.0/24:

| Roteador | IP da Interface | Prioridade PIM |
|----------|-----------------|----------------|
| R1       | 192.168.10.1    |       1        |
| R2       | 192.168.10.2    |       1        |
| R3       | 192.168.10.3    |       5        |

âž¡ï¸ Resultado:  

O R3 serÃ¡ o Designated Router, pois tem maior prioridade (5).  
Se R3 cair, a eleiÃ§Ã£o Ã© refeita: o DR passa a ser R2 (maior IP entre os restantes).  

### Resumo rÃ¡pido

| Etapa | DescriÃ§Ã£o                                                  |
|-------|------------------------------------------------------------|
| 1ï¸âƒ£    | Todos enviam mensagens PIM Hello                           |
| 2ï¸âƒ£    | Comparam prioridade (dr-priority)                          |
| 3ï¸âƒ£    | Empate â†’ vence o maior IP da interface                     |
| 4ï¸âƒ£    | Roteador vencedor se torna o DR                            |
| 5ï¸âƒ£    | DR Ã© responsÃ¡vel pelo trÃ¡fego multicast e comunicaÃ§Ã£o IGMP |
| 6ï¸âƒ£    | Se o DR falhar â†’ nova eleiÃ§Ã£o automÃ¡tica                   |

Agora vamos confirmar isso com o **Whireshark** Vamos ligar ele na interface de R01 que estÃ¡ ligada ao nosso HOST01 (SERVER) e vamos procurar pelas mensagens Hello do protocolo PIM.  

![hello](Imagens/03.png)  

Como podemos ver, a mensagem **Hello** Ã© originada do IP 192.168.0.254, que Ã© o IP do nosso SERVER com origem para **224.0.0.13**  

## EndereÃ§o Multicast 224.0.0.13

| Campo               | Valor                                              |
|---------------------|----------------------------------------------------|
| EndereÃ§o IPv4       | 224.0.0.13                                         |
| Nome reservado      | ALL-PIM-ROUTERS                                    |
| Protocolo associado | Protocol Independent Multicast (PIM)               |
| Escopo              | Local-link (nÃ£o Ã© roteÃ¡vel)                        |
| FunÃ§Ã£o              | ComunicaÃ§Ã£o entre roteadores PIM no mesmo segmento |  

E dentro do pacote:  

- Option 19: DR Priority: 1
- Option 20: Generation ID: 488683522
- Option 21: State-Refresh: Version = 1, Interval = 0s

Essas opÃ§Ãµes sÃ£o usadas justamente para o processo de eleiÃ§Ã£o do DR e detecÃ§Ã£o de vizinhos.  

**ðŸ” O papel do endereÃ§o 224.0.0.13 em resumo**

| FunÃ§Ã£o                           | DescriÃ§Ã£o                                                                                                          |
|----------------------------------|--------------------------------------------------------------------------------------------------------------------|
| Descoberta de vizinhos           | Os roteadores PIM enviam Hellos para 224.0.0.13 e escutam nesse grupo para saber quem mais estÃ¡ no mesmo segmento. |
| EleiÃ§Ã£o de DR                    | As mensagens Hello trocadas via 224.0.0.13 contÃªm o campo de prioridade que define quem serÃ¡ o DR.                 |
| Troca de informaÃ§Ãµes de controle | Outras mensagens PIM (Join/Prune, Assert, Register Stop, etc.) tambÃ©m usam esse grupo.                             |
| Escopo local (nÃ£o roteÃ¡vel)      | Pacotes para 224.0.0.13 nunca saem da rede local â€” sÃ£o sempre TTL=1.                                               |  

### RevisÃ£o

A tabela abaixo mostra outros endereÃ§os multicast da faixa 224.0.0.x, usados por protocolos de roteamento e gerenciamento:

| EndereÃ§o   | Nome                  | Usado por                 |
|------------|-----------------------|---------------------------|
| 224.0.0.1  | All Hosts             | Todos os hosts multicast  |
| 224.0.0.2  | All Routers           | Todos os roteadores       |
| 224.0.0.5  | All OSPF Routers      | OSPF                      |
| 224.0.0.6  | OSPF DR/BDR Routers   | OSPF                      |
| 224.0.0.9  | RIPng Routers         | RIPng                     |
| 224.0.0.10 | EIGRP Routers         | EIGRP                     |
| 224.0.0.13 | All PIM Routers       | PIMv2                     |
| 224.0.0.18 | VRRP Routers          | VRRP                      |  

### Resumo prÃ¡tico

ðŸ”¹ Quem envia: todo roteador com ip pim dense-mode (ou sparse, etc.) ativo em uma interface.  
ðŸ”¹ Quem recebe: todos os roteadores PIM do mesmo segmento (escutando 224.0.0.13).  
ðŸ”¹ TTL = 1: os pacotes nunca sÃ£o roteados.  

Usado para:

- Descoberta de vizinhos PIM
- EleiÃ§Ã£o de DR
- ComunicaÃ§Ã£o de controle  

Agora que entendemos, o inicio do processo, vamos analisar a tabela de roteamento multicast. Aqui Ã© importante que esse Ã© o ponto de criaÃ§Ã£o de nossa Ã¡rvore multicast.  
O comando fica:  

> R01#show ip mroute  

E o resultado Ã© a saÃ­da:  

> IP Multicast Routing Table
> Flags: D - Dense, S - Sparse, B - Bidir Group, s - SSM Group, C - Connected,
       L - Local, P - Pruned, R - RP-bit set, F - Register flag,
       T - SPT-bit set, J - Join SPT, M - MSDP created entry,
       X - Proxy Join Timer Running, A - Candidate for MSDP Advertisement,
       U - URD, I - Received Source Specific Host Report,
       Z - Multicast Tunnel, z - MDT-data group sender,
       Y - Joined MDT-data group, y - Sending to MDT-data group
> Outgoing interface flags: H - Hardware switched, A - Assert winner
 Timers: Uptime/Expires
 Interface state: Interface, Next-Hop or VCD, State/Mode
>
> (*, 224.0.1.40), 00:00:20/00:02:40, RP 0.0.0.0, flags: DCL
  Incoming interface: Null, RPF nbr 0.0.0.0
  Outgoing interface list:
    FastEthernet0/0, Forward/Dense, 00:00:20/00:00:00

> R01#
